# Transform Army AI - Environment Variables
# Copy this file to .env in your project root

# ===== LLM Provider API Keys =====
# Configure at least ONE provider to enable Agent Forge functionality

# OpenAI API (for OpenAI provider - gpt-4o, gpt-4, etc.)
OPENAI_API_KEY=your_openai_api_key_here

# OpenRouter API (for multi-model provider - mistral, llama, etc.)
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Anthropic Claude API (for Claude models)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# ===== Local LLM Providers (No API Key Required) =====
# These run on your local machine - make sure the service is running first

# Ollama (Local) - default: http://localhost:11434
# Download models: ollama pull llama3.1
OLLAMA_BASE_URL=http://localhost:11434

# LM Studio (Local) - default: http://localhost:1234
# Start the LM Studio server before using
LMSTUDIO_BASE_URL=http://localhost:1234

# ===== Optional: Slack Integration =====
# Uncomment and configure these for Slack integration in deployed missions
# SLACK_BOT_TOKEN=xoxb-your-slack-bot-token
# SLACK_APP_TOKEN=xapp-your-slack-app-token
# SLACK_CHANNEL_ID=C1234567890

# ===== Optional: Vector Database (for Learning Organization) =====
# CHROMA_HOST=localhost
# CHROMA_PORT=8000

# ===== Usage Notes =====
# - You need AT LEAST one LLM provider configured
# - Web API Providers (require API keys):
#   * OpenAI: Best quality, industry standard
#   * OpenRouter: Multi-model access, competitive pricing
#   * Anthropic: Strong reasoning capabilities
# - Local Providers (no API keys, run on your machine):
#   * Ollama: Free, open-source, supports many models (llama3.1, mistral, etc.)
#   * LM Studio: User-friendly GUI, supports GGUF models

